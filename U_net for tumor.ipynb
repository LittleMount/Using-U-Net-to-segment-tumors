{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整体流程\n",
    "\n",
    "流程：导入包 -> 读取数据 -> 查看数据是否准确 -> 分离训练集和测试 -> 构建网络  \n",
    "                     -> 编译 -> 训练 -> 可视化 -> 测试 -> 查看结果\n",
    "\n",
    "# 导入包\n",
    "系统文件操作函数：\n",
    "a, b, c = next(os.walk(filepath))    \n",
    "#第一个返回当前目录，第二个值返回当前目录的子目录名称，第三个值为当前目录下的文件名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    " \n",
    "path_mask = \"C:/Users/liu/Desktop/U-net网络分割大肠癌/数据集1/\"    #1001/arterial phase/\"\n",
    "path_img = \"C:/Users/liu/Desktop/U-net网络分割大肠癌/all_data/\"\n",
    "phase = \"/arterial phase/\"\n",
    "#dir_a, dir_b, temp = next(os.walk(path_img))   #获取路径\n",
    "#filename1 = next(os.walk(path_img+dir_b[1]+phase))[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义读取数据的函数\n",
    "读取图像的函数是\n",
    "from keras.preprocessing.image import load_img\n",
    "img = load_img(filename, color_mode='grayscale')\n",
    "img = np.array(img)\n",
    "\n",
    "# 如果c中包含多个类型的数据怎么办？\n",
    "流程：构建路径 -> 读取路径内文件夹名称 -> 查看名称 -> 利用列表推导是求得特定类型的名称\n",
    "\n",
    "path = \"C:/Users/liu/Desktop/U-net网络分割大肠癌/数据集1/1001/arterial phase/\"\n",
    "filename_list = next(os.walk(path))[2]\n",
    "\n",
    "测试过程：\n",
    "temp = filename_list[0].lower()\n",
    "print(temp)\n",
    "b = \".dcm\" in temp \n",
    "print(b)\n",
    "\n",
    "可行方案：\n",
    "mask_name = [x for x in filename_list if '.png' in x.lower()]  #lower() 将大写转小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(path, phase):\n",
    "    n = -1\n",
    "    X = np.zeros((3057, 128, 128, 1), dtype='float32')\n",
    "    ids = next(os.walk(path))[1]   #获取路径\n",
    "    for id in tqdm(ids):\n",
    "        temp_path = path+id+phase\n",
    "        file_id = next(os.walk(temp_path))[2]\n",
    "        file_id = [x for x in file_id if '.png' in x.lower()]\n",
    "        for f_id in file_id:\n",
    "            n += 1\n",
    "            filename = temp_path+f_id    #计算图像的名称\n",
    "            img = load_img(filename, color_mode='grayscale')    #读取图像\n",
    "            x_img = np.array(img)/255\n",
    "            x_img = resize(x_img[256:,128:384], (128,128,1), mode='constant', preserve_range=True)\n",
    "            X[n] = x_img    #\n",
    "    return X\n",
    "x_train = get_data(path_img, phase)\n",
    "y_train = get_data(path_mask, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数组\n",
    "np.save('data_small.npy', [x_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([100,100])\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = np.zeros([100, 100])\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax[0].imshow(a, cmap='gray')\n",
    "ax[1].imshow(a, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看数据是否准确\n",
    "随机读取一张图片 -> 子图像显示 -> 绘制边界 -> 显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(x_train))  #随机正整数\n",
    "print(idx)\n",
    "img = x_train[idx].squeeze()    #获取图片\n",
    "mask = y_train[idx].squeeze()\n",
    "has_mask = y_train[idx].max()>0  #查看是否有掩膜\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "\n",
    "ax[0].imshow(img, cmap = 'gray')\n",
    "if has_mask:\n",
    "    ax[0].contour(mask, colors='r', levels=[0.5])   #在原图绘制掩膜曲线\n",
    "ax[0].set_title('Original')\n",
    "\n",
    "ax[1].imshow(mask, cmap = 'gray')    #绘制掩膜图像\n",
    "ax[1].set_title('Mask')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分离训练集和测试集\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x_train, x_mask, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建网络\n",
    "定义conv2d_block函数  \n",
    "卷积层 -> 归一化(再激活函数) -> 卷积层 -> 归一化(再激活函数)  \n",
    "定义get_unet函数  \n",
    "conv2d_block -> Maxpooling2D -> Dropout2D -> ... 4次maxpooling ... -> Conv2DTranspose -> concatenate -> Dropout  \n",
    "-> conv2d_block -> ...4次Conv2DTranspose -> 1大小filter输出output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters=16, kernel_size=3, batchnorm=True):\n",
    "    # the first layer\n",
    "    x = Conv2D(n_filters, kernel_size, padding='same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # the second layer\n",
    "    x = Conv2D(n_filters, kernel_size, padding='same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    X = Activation('relu')(x)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    # contracting path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3,3), strides=(2,2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    outputs = Conv2D(1, (1,1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img],outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编译\n",
    "输入一张测试图片，编译网络，查看网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载\n",
    "input_img = Input((128, 128,1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input((128, 128,1), name='img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练网络\n",
    "设置训练的模式 -> 设置训练参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-tgs-salt.h5', verbose=1,\n",
    "                    save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.fit(x_train, y_train, batch_size=32, epochs=100, callbacks = callbacks,\n",
    "                   validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练过程的可视化\n",
    "显示loss数据的变化曲线  \n",
    "从results.history['loss']获取loss的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label='loss')\n",
    "plt.plot(results.history[\"val_loss\"], label = 'val_loss')\n",
    "plt.plot(np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), '-')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试集的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练好的模型\n",
    "# Load best model\n",
    "model.load_weights('model-tgs-salt.h5')\n",
    "\n",
    "# Evaluate on validation set (this must be equals to the best log_loss)\n",
    "model.evaluate(x_valid, y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络预测\n",
    "# Predict on train, and val\n",
    "preds_train = model.predict(x_train,verbose=1)\n",
    "preds_val = model.predict(x_valid, verbose=1)\n",
    "\n",
    "# threshold predictions\n",
    "y_train = (y_train>0.3).astype(np.uint8)\n",
    "preds_train_t = (preds_train>0.3).astype(np.uint8)\n",
    "preds_val_t = (preds_val>0.3).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = (y_valid>0.3).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看分割效果\n",
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "        while y[ix].max() == 0:\n",
    "            ix = random.randint(0, len(X))\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='gray')\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='r')\n",
    "    ax[0].set_title('Ground Truth')\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze())\n",
    "    ax[1].set_title('Mask of doctor')\n",
    "\n",
    "    ax[2].imshow(preds[ix, ..., 0], vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[2].contour(binary_preds[ix].squeeze(), colors='r')\n",
    "    ax[2].set_title('Prediction')\n",
    "\n",
    "    ax[3].imshow(binary_preds[ix].squeeze())\n",
    "    ax[3].set_title('mask of prediction')\n",
    "\n",
    "# 训练样本的分割效果\n",
    "plot_sample(x_train, y_train, preds_train, preds_train_t)\n",
    "\n",
    "# 测试样本的分割效果\n",
    "for i in range(3):\n",
    "    plot_sample(x_valid, y_valid, preds_val, preds_val_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计图片个数\n",
    "def get_data(path_img=path_img, path_mask=path_mask, phase=phase):\n",
    "    count = 0;\n",
    "    ids = next(os.walk(path_img))[1]   #获取路径\n",
    "    for id in ids:\n",
    "        temp_path = path_img+id+phase\n",
    "        file_id = next(os.walk(temp_path))[2]\n",
    "        count += len(file_id)\n",
    "    return count\n",
    "x = get_data()    \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = np.array(img)\n",
    "b = a[256:,128:384]\n",
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图片的其他代码的部分程序\n",
    "for filename in ids:\n",
    "    if \".png\" in filename.lower():  # check whether the file's png\n",
    "        filename_list.append(os.path.join(path,filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
